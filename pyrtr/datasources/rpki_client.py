"""Interface towards the rpki-client JSON file"""

import asyncio
import base64
import logging
import os
from collections.abc import Generator
from datetime import datetime, timedelta, timezone
from typing import TypedDict
from urllib.parse import urlparse

import aiofiles
import aiohttp
import xxhash
import orjson
from typing_extensions import override

from pyrtr.datasources.datasource import Data, Datasource

logger = logging.getLogger(__name__)


class JSONMetadata(TypedDict):
    """File metadata"""

    buildmachine: str
    buildtime: str
    elapsedtime: int
    usertime: int
    systemtime: int
    roas: int
    failedroas: int
    invalidroas: int
    aspas: int
    failedaspas: int
    invalidaspas: int
    bgpsec_pubkeys: int
    certificates: int
    invalidcertificates: int
    nonfunctionalcas: int
    taks: int
    tals: int
    invalidtals: int
    talfiles: list[str]
    manifests: int
    failedmanifests: int
    crls: int
    gbrs: int
    repositories: int
    vrps: int
    uniquevrps: int
    vsps: int
    uniquevsps: int
    vaps: int
    uniquevaps: int
    cachedir_new_files: int
    cachedir_del_files: int
    cachedir_del_dirs: int
    cachedir_superfluous_files: int
    cachedir_del_superfluous_files: int


class ROA(TypedDict):
    """RPKI ROA"""

    asn: int
    prefix: str
    maxLength: int
    ta: str
    expires: int


class BGPSecKey(TypedDict):
    """BGPSec key"""

    asn: int
    ski: str
    pubkey: str
    ta: str
    expires: int


class NonFuncCA(TypedDict):
    """Non functional CA"""

    location: str
    ta: str
    caRepository: str
    rpkiManifest: str
    ski: str


class ASPA(TypedDict):
    """ASPA object"""

    customer_asid: int
    expires: int
    providers: list[int]


class JSONContent(TypedDict):
    """Defines the fields in the JSON file"""

    metadata: JSONMetadata
    roas: dict[str, ROA]
    bgpsec_keys: dict[str, BGPSecKey]
    nonfunc_cas: list[NonFuncCA]
    aspas: dict[str, ASPA]


class JSON(Data):
    """Extends the Data structure to represent a JSON file"""

    content: JSONContent


class RPKIClient(Datasource):
    """
    Interface for the JSON file as generated by rpki_client.
    """

    def __init__(self, version: int, location: str | os.PathLike[str], expire: int = 7200):
        """
        Arguments:
        ----------
        version: int
            The RTR version number
        json_file: str | os.PathLike[str]
            The path for the RPKI-Client JSON file
        expire: int
            The RTR expire time
        """
        super().__init__(version, location, expire)

        self.copies: dict[int, JSON] = {}

    def _calculate_roa_diffs(
        self, old_roas: dict[str, ROA], new_roas: dict[str, ROA]
    ) -> Generator[bytes]:
        """
        Calculates the differences in the ROAs between the old and the new JSON file and yields
        prefix PDUs.

        Arguments:
        ----------
        old_roas: dict[str, ROA]
            ROAs in the old JSON file
        new_roas: dict[str, ROA]
            ROAs in the new JSON file

        Returns:
        --------
        Generator[bytes]: Yields serialized prefix PDUs
        """
        old_roas_keys: set[str] = set(old_roas.keys())
        new_roas_keys: set[str] = set(new_roas.keys())

        # Generate hashabale data structures
        # Yield changes
        removed_roa_keys: set[str] = old_roas_keys - new_roas_keys
        for key in removed_roa_keys:
            old_roa = old_roas[key]
            yield self.serialize_prefix(old_roa["prefix"], old_roa["asn"], old_roa["maxLength"], 0)

        added_roa_keys: set[str] = new_roas_keys - old_roas_keys
        for key in added_roa_keys:
            new_roa = new_roas[key]
            yield self.serialize_prefix(new_roa["prefix"], new_roa["asn"], new_roa["maxLength"], 1)

    def _calculate_bgpsec_key_diffs(
        self,
        old_bgpsec_keys: dict[str, BGPSecKey],
        new_bgpsec_keys: dict[str, BGPSecKey],
    ) -> Generator[bytes]:
        """
        Calculates the differences in the BGPSec Keys between the old and the new JSON file and
        yields prefix PDUs.

        Arguments:
        ----------
        old_bgpsec_keys: dict[str, BGPSecKey]
            BGPSec Keys in the old JSON file
        new_bgpsec_keys: dict[str, BGPSecKey]
            BGPSec Keys in the new JSON file

        Returns:
        --------
        Generator[bytes]: Yields serialized router key PDUs
        """
        # Generate hashabale data structures
        old_bgpsec_key_keys: set[str] = set(old_bgpsec_keys.keys())
        new_bgpsec_key_keys: set[str] = set(new_bgpsec_keys.keys())

        # Yield changes
        removed_bgpsec_key_keys: set[str] = old_bgpsec_key_keys - new_bgpsec_key_keys
        for key in removed_bgpsec_key_keys:
            old_bgpsec_key = old_bgpsec_keys[key]
            # This is not stated anywhere in the rpki-client docs
            ski = base64.b16decode(old_bgpsec_key["ski"], casefold=True)
            # This is not stated anywhere in the rpki-client docs
            pubkey = base64.b64decode(old_bgpsec_key["pubkey"])
            yield self.serialize_router_key(old_bgpsec_key["asn"], ski, pubkey, 0)

        added_bgpsec_key_keys: set[str] = new_bgpsec_key_keys - old_bgpsec_key_keys
        for key in added_bgpsec_key_keys:
            new_bgpsec_key = old_bgpsec_keys[key]
            # This is not stated anywhere in the rpki-client docs
            ski = base64.b16decode(new_bgpsec_key["ski"], casefold=True)
            # This is not stated anywhere in the rpki-client docs
            pubkey = base64.b64decode(new_bgpsec_key["pubkey"])
            yield self.serialize_router_key(new_bgpsec_key["asn"], ski, pubkey, 1)

    async def _reduce_roas(self, roas: list[ROA]) -> dict[str, ROA]:
        """
        Reduces a list of ROAs into a dict of unique and valid ROAs.

        Arguments:
        ----------
        roas: list[ROA]
            The ROAs to reduce

        Returns:
        --------
        dict[str, ROA]: The reduced ROAs
        """
        current_timestamp = datetime.now(timezone.utc).timestamp()

        reduced_roas: dict[str, ROA] = {}
        for roa in roas:
            if current_timestamp >= roa["expires"]:
                continue
            key = f'{roa["asn"]}|{roa["prefix"]}|{roa["maxLength"]}'
            reduced_roas[key] = roa
            await asyncio.sleep(0)

        return reduced_roas

    async def _reduce_bgpsec_keys(self, bgpsec_keys: list[BGPSecKey]) -> dict[str, BGPSecKey]:
        """
        Reduces a list of BGPSec Keys into a dict of unique and valid BGPSec Keys.

        Arguments:
        ----------
        roas: list[BGPSecKey]
            The BGPSec Keys to reduce

        Returns:
        --------
        dict[str, BGPSecKey]: The reduced BGPSec Keys
        """
        current_timestamp = datetime.now(timezone.utc).timestamp()

        reduced_bgpsec_keys: dict[str, BGPSecKey] = {}
        for bgpsec_key in bgpsec_keys:
            if current_timestamp >= bgpsec_key["expires"]:
                continue
            key = f'{bgpsec_key["asn"]}|{bgpsec_key["ski"]}|{bgpsec_key["pubkey"]}'
            reduced_bgpsec_keys[key] = bgpsec_key
            await asyncio.sleep(0)

        return reduced_bgpsec_keys

    async def _read_file(self) -> bytes:
        """
        Reads the JSON file either locally or remotely if self.location is a URL

        Returns:
        --------
        bytes: The content of the JSON file
        """
        try:
            # Test if the `location` is a URL
            urlparse(self.location)
            async with aiohttp.ClientSession() as session:
                async with session.get(self.location) as response:
                    return (await response.text()).encode("utf-8")
        except ValueError:
            async with aiofiles.open(self.location, mode="rb") as file:
                return await file.read()

    @override
    async def parse(self) -> Data:
        """
        Loads the content of the file. Remove expired ROAs and BGPSec Keys

        Returns:
        --------
        JSON: The JSON file
        """
        data: bytes = await self._read_file()

        # This is not JSONContent yet, it will be after we convert ROAs, BGPSec Keys and ASPAS to
        # dictionaries
        json_content = orjson.loads(data)  # pylint: disable=no-member

        # Check if the file is expired
        buildtime = datetime.fromisoformat(json_content["metadata"]["buildtime"])
        expire_moment = buildtime + timedelta(seconds=self.expire)

        # Set values baseline
        roas: dict[str, ROA] = {}
        bgpsec_keys: dict[str, BGPSecKey] = {}
        aspas: dict[str, ASPA] = {}

        # Parse values
        if datetime.now(timezone.utc) > expire_moment:
            # The file is expired and so are VRPs, BGPSec Keys and ASPAs
            logger.warning("The JSON file is expired")
        else:
            match self.version:
                case 0:
                    # Parse ROAs and do not parse BGPSec Keys
                    roas = await self._reduce_roas(json_content["roas"])
                case 1:
                    # Parse ROAs
                    roas = await self._reduce_roas(json_content["roas"])
                    # Parse BGPSec Keys
                    bgpsec_keys = await self._reduce_bgpsec_keys(json_content["bgpsec_keys"])
                case _:
                    raise ValueError(f"Unsupported version number: {self.version}")

        # Update JSON
        json_content["roas"] = roas
        json_content["bgpsec_keys"] = bgpsec_keys
        json_content["aspas"] = aspas

        # Calculate hash
        json_hash: str = xxhash.xxh64(
            "".join(roas.keys()) + "".join(bgpsec_keys.keys()) + "".join(aspas.keys())
        ).hexdigest()

        vrps: list[bytes] = []
        for roa in roas.values():
            vrps.append(self.serialize_prefix(roa["prefix"], roa["asn"], roa["maxLength"], 1))
            await asyncio.sleep(0)

        router_keys: list[bytes] = []
        for bgpsec_key in bgpsec_keys.values():
            # This is not stated anywhere in the rpki-client docs
            ski = base64.b16decode(bgpsec_key["ski"], casefold=True)
            # This is not stated anywhere in the rpki-client docs
            pubkey = base64.b64decode(bgpsec_key["pubkey"])
            router_keys.append(self.serialize_router_key(bgpsec_key["asn"], ski, pubkey, 1))
            await asyncio.sleep(0)

        return {
            "content": json_content,
            "hash": json_hash,
            "timestamp": buildtime.timestamp(),
            "diffs": {"vrps": [], "router_keys": []},
            "serialized": {"vrps": vrps, "router_keys": router_keys},
        }

    async def reload(self) -> bool:
        """
        Purge old JSON files, load the new one, calculate diffs, and increment serial.

        Return:
        -------
        bool: True if the process completed successfully.
        """
        await self.purge()

        try:
            new_json: JSON = await self.parse()
        except (orjson.JSONDecodeError, KeyError) as error:  # pylint: disable=no-member
            raise ValueError(f"Unable to load the file: {error}") from error

        # Check if the new and the current file are the same
        try:
            if new_json["hash"] == self.copies[self.serial]["hash"]:
                return False
        except KeyError:
            pass

        # Calculate diffs
        for old_json in self.copies.values():
            # Do not waste CPU cycles if not needed
            match self.version:
                case 0:
                    vrps = self._calculate_roa_diffs(
                        new_roas=new_json["content"]["roas"],
                        old_roas=old_json["content"]["roas"],
                    )
                    old_json["diffs"] = {"vrps": list(vrps), "router_keys": []}
                case 1:
                    vrps = self._calculate_roa_diffs(
                        new_roas=new_json["content"]["roas"],
                        old_roas=old_json["content"]["roas"],
                    )
                    router_keys = self._calculate_bgpsec_key_diffs(
                        new_bgpsec_keys=new_json["content"]["bgpsec_keys"],
                        old_bgpsec_keys=old_json["content"]["bgpsec_keys"],
                    )
                    old_json["diffs"] = {"vrps": list(vrps), "router_keys": list(router_keys)}
                case _:
                    raise ValueError(f"Unsupported version number: {self.version}")

            # Delete the old serialized data to spare memory
            old_json["serialized"]["vrps"] = []
            old_json["serialized"]["router_keys"] = []

        self.vrps = new_json["serialized"]["vrps"]
        self.router_keys = new_json["serialized"]["router_keys"]

        self.serial = self.serial + 1
        self.copies[self.serial] = new_json

        await self.update_prometheus()

        logger.info("Serial for V%d changed to: %d", self.version, self.serial)

        return True
