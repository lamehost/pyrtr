"""Interface towards the rpki-client JSON file"""

import base64
import hashlib
import logging
import os
from collections.abc import Generator
from datetime import datetime, timezone
from ipaddress import ip_network
from typing import Tuple, TypedDict

import aiofiles
import orjson

from pyrtr.rtr.pdu import ipv4_prefix, ipv6_prefix, router_key

logger = logging.getLogger(__name__)


class JSONMetadata(TypedDict):
    """File metadata"""

    buildmachine: str
    buildtime: str
    elapsedtime: int
    usertime: int
    systemtime: int
    roas: int
    failedroas: int
    invalidroas: int
    aspas: int
    failedaspas: int
    invalidaspas: int
    bgpsec_pubkeys: int
    certificates: int
    invalidcertificates: int
    nonfunctionalcas: int
    taks: int
    tals: int
    invalidtals: int
    talfiles: list[str]
    manifests: int
    failedmanifests: int
    crls: int
    gbrs: int
    repositories: int
    vrps: int
    uniquevrps: int
    vsps: int
    uniquevsps: int
    vaps: int
    uniquevaps: int
    cachedir_new_files: int
    cachedir_del_files: int
    cachedir_del_dirs: int
    cachedir_superfluous_files: int
    cachedir_del_superfluous_files: int


class ROA(TypedDict):
    """RPKI ROA"""

    asn: int
    prefix: str
    maxLength: int
    ta: str
    expires: int


class BGPSecKey(TypedDict):
    """BGPSec key"""

    asn: int
    ski: str
    pubkey: str
    ta: str
    expires: int


class NonFuncCA(TypedDict):
    """Non functional CA"""

    location: str
    ta: str
    caRepository: str
    rpkiManifest: str
    ski: str


class ASPA(TypedDict):
    """ASPA object"""

    customer_asid: int
    expires: int
    providers: list[int]


class JSONContent(TypedDict):
    """Defines the fields in the JSON file"""

    metadata: JSONMetadata
    roas: list[ROA]
    bgpsec_keys: list[BGPSecKey]
    nonfunc_cas: list[NonFuncCA]
    aspas: list[ASPA]


class JSONDiffs(TypedDict):
    """Defines the data structure representing the objects in the JSON file"""

    vrps: list[bytes]
    router_keys: list[bytes]


class JSON(TypedDict):
    """Defines the data structure representing the JSON file"""

    content: JSONContent
    hash: str
    timestamp: float
    diffs: JSONDiffs


class RPKIClient:
    """
    Interface for the JSON file as generated by rpki_client.

    Arguments:
    ----------
    version: int
        The version identifier
    """

    # Serial equals 0 means no data is available
    serial: int = 0
    json: dict[int, JSON] = {}
    vrps: list[bytes] = []
    router_keys: list[bytes] = []
    last_update: str | None = None
    versions: int

    def __init__(self, version: int):
        self.version = version

    def calculate_roa_diffs(
        self, old_json_roas: list[ROA], new_json_roas: list[ROA]
    ) -> Generator[bytes]:
        """
        Calculates the differences in the ROAs between the old and the new JSON file and yields
        prefix PDUs.

        Arguments:
        ----------
        old_json_roas: list[ROA]
            ROAs in the old JSON file
        new_json_roas: list[ROA]
            ROAs in the new JSON file

        Returns:
        --------
        Generator[bytes]: Yields serialized prefix PDUs
        """
        # Generate hashabale data structures
        old_roas: dict[Tuple[int, str, int], ROA] = {
            key: roa
            for roa in old_json_roas
            if (key := (roa["asn"], roa["prefix"], roa["maxLength"]))
        }

        new_roas: dict[Tuple[int, str, int], ROA] = {
            key: roa
            for roa in new_json_roas
            if (key := (roa["asn"], roa["prefix"], roa["maxLength"]))
        }

        # Yield changes
        removed_roa_keys: set[Tuple[int, str, int]] = set(old_roas) - set(new_roas)
        for key in removed_roa_keys:
            yield self.serialize_vrp(old_roas[key], 0)

        added_roa_keys: set[Tuple[int, str, int]] = set(new_roas) - set(old_roas)
        for key in added_roa_keys:
            yield self.serialize_vrp(new_roas[key], 1)

    def calculate_bgpsec_key_diffs(
        self,
        old_json_bgpsec_keys: list[BGPSecKey],
        new_json_bgpsec_keys: list[BGPSecKey],
    ) -> Generator[bytes]:
        """
        Calculates the differences in the BGPSec Keys between the old and the new JSON file and
        yields prefix PDUs.

        Arguments:
        ----------
        old_json_roas: list[BGPSecKey]
            BGPSec Keys in the old JSON file
        new_json_roas: list[BGPSecKey]
            BGPSec Keys in the new JSON file

        Returns:
        --------
        Generator[bytes]: Yields serialized router key PDUs
        """
        # Generate hashabale data structures
        old_bgpsec_keys: dict[Tuple[int, str, str], BGPSecKey] = {
            key: bgpsec_key
            for bgpsec_key in old_json_bgpsec_keys
            if (key := (bgpsec_key["asn"], bgpsec_key["ski"], bgpsec_key["pubkey"]))
        }

        new_bgpsec_keys: dict[Tuple[int, str, str], BGPSecKey] = {
            key: bgpsec_key
            for bgpsec_key in new_json_bgpsec_keys
            if (key := (bgpsec_key["asn"], bgpsec_key["ski"], bgpsec_key["pubkey"]))
        }

        # Yield changes
        removed_bgpsec_key_keys: set[Tuple[int, str, str]] = set(old_bgpsec_keys) - set(
            new_bgpsec_keys
        )
        for key in removed_bgpsec_key_keys:
            yield self.serialize_bgpsec_key(old_bgpsec_keys[key], 0)

        added_bgpsec_key_keys: set[Tuple[int, str, str]] = set(new_bgpsec_keys) - set(
            old_bgpsec_keys
        )
        for key in added_bgpsec_key_keys:
            yield self.serialize_bgpsec_key(new_bgpsec_keys[key], 1)

    def serialize_unique_bgpsec_key(self, bgpsec_keys: list[BGPSecKey]) -> Generator[bytes]:
        """
        Serialize a list of BGPSec Keus, while removing duplicates. The flags field is set to 1.

        Arguments:
        ----------
        roas: list[BGPSecKey]
            The list of BGPSec Keys to serialize

        Returns:
        --------
            Generator[bytes]: Serialized BGPSec Keys
        """
        # Mapping everything into a dict and then returning the values removes the duplicates
        unique_bgpsec_keys = {
            (bgpsec_key["asn"], bgpsec_key["ski"], bgpsec_key["pubkey"]): bgpsec_key
            for bgpsec_key in bgpsec_keys
        }
        for bgpsec_key in unique_bgpsec_keys.values():
            yield self.serialize_bgpsec_key(bgpsec_key, 1)

    def serialize_unique_vrps(self, roas: list[ROA]) -> Generator[bytes]:
        """
        Serialize a list of ROAS into VRPs, while removing duplicates. The flags field is set to 1.

        Arguments:
        ----------
        roas: list[ROA]
            The list of ROAs to serialize

        Returns:
        --------
            Generator[bytes]: Serialized VRPs
        """
        # Mapping everything into a dict and then returning the values removes the duplicates
        unique_roas = {(roa["asn"], roa["prefix"], roa["maxLength"]): roa for roa in roas}
        for roa in unique_roas.values():
            yield self.serialize_vrp(roa, 1)

    def serialize_bgpsec_key(self, bgpsec_key: BGPSecKey, flags: int) -> bytes:
        """
        Serialize the BGPSec Key to bytes

        Arguments:
        ----------
        bgpsec_key: BGPSec Key
            The BGPSec Key to serialize

        flags: int
            Either 0 for withdrawal or 1 for advertisement

        Returns:
        --------
        bytes: The serialized BGPSec Key
        """
        # This is not stated anywhere in the rpki-client docs
        ski = base64.b16decode(bgpsec_key["ski"])
        pubkey = base64.b64decode(bgpsec_key["pubkey"])

        return router_key.serialize(
            version=self.version,
            flags=flags,
            ski=ski,
            spki=pubkey,
            asn=bgpsec_key["asn"],
        )

    def serialize_vrp(self, roa: ROA, flags: int) -> bytes:
        """
        Serialize the ROA to bytes

        Arguments:
        ----------
        roa: ROA
            The ROA to serialize

        flags: int
            Either 0 for withdrawal or 1 for advertisement

        Returns:
        --------
        bytes: The serialized ROA
        """
        prefix = ip_network(roa["prefix"])
        if prefix.version == 4:
            return ipv4_prefix.serialize(
                version=self.version,
                prefix=prefix.network_address.packed,
                prefix_length=prefix.prefixlen,
                flags=flags,
                max_length=roa["maxLength"],
                asn=roa["asn"],
            )

        return ipv6_prefix.serialize(
            version=self.version,
            prefix=prefix.network_address.packed,
            prefix_length=prefix.prefixlen,
            flags=flags,
            max_length=roa["maxLength"],
            asn=roa["asn"],
        )

    def purge(self, expire: int = 7200):
        """
        Delete expired JSON files

        Arguments:
        ----------
        expire: int
            The amount of seconds after which a file is purged. Default: 7200
        """
        self.json = {
            _serial: _json
            for _serial, _json in self.json.items()
            if _json["timestamp"] > datetime.now(timezone.utc).timestamp() - expire
        }

    async def load(self, path: str | os.PathLike[str]) -> bool:
        """
        Loads the content of the file. Ignores files that have been already loaded.

        Arguments:
        ----------
        path: str | os.PathLike[str]
            Path to the file

        Returns:
        --------
        bool: True if the file was loaded, False if it was ignored
        """
        async with aiofiles.open(path, mode="rb") as file:
            data: bytes = await file.read()

        new_json_hash = hashlib.sha256(data).hexdigest()
        new_json: JSONContent = orjson.loads(data)  # pylint: disable=no-member

        # Check if the new and the current file are the same
        try:
            if new_json_hash == self.json[self.serial]["hash"]:
                return False
        except KeyError:
            pass

        for serial, old_json in self.json.items():
            # Re-generate diffs
            vrps: list[bytes] = list(
                self.calculate_roa_diffs(old_json["content"]["roas"], new_json["roas"])
            )
            if self.version >= 1:
                router_keys: list[bytes] = list(
                    self.calculate_bgpsec_key_diffs(
                        old_json["content"]["bgpsec_keys"], new_json["bgpsec_keys"]
                    )
                )
            else:
                router_keys = []

            # Add a new list of changes
            self.json[serial]["diffs"] = JSONDiffs(vrps=vrps, router_keys=router_keys)

        # Update the list of VRPs
        self.vrps = list(self.serialize_unique_vrps(roas=new_json["roas"]))

        if self.version >= 1:
            # Update the list of Router Keys
            self.router_keys = list(
                self.serialize_unique_bgpsec_key(bgpsec_keys=new_json["bgpsec_keys"])
            )
        else:
            self.router_keys = []

        # Save new JSON
        self.serial = self.serial + 1
        self.last_update = datetime.now(timezone.utc).isoformat()
        self.json[self.serial] = JSON(
            content=new_json,
            hash=new_json_hash,
            timestamp=datetime.now(timezone.utc).timestamp(),
            diffs={"vrps": [], "router_keys": []},
        )
        logger.info("Serial for version %d changed to: %d", self.version, self.serial)

        return True
