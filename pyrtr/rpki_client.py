"""Interface towards the rpki-client JSON file"""

import hashlib
import logging
import os
from datetime import datetime, timezone
from ipaddress import ip_network
from typing import Tuple, TypedDict

import aiofiles
import orjson

from .pdu import ipv4_prefix, ipv6_prefix

logger = logging.getLogger(__name__)


class JSONMetadata(TypedDict):
    """File metadata"""

    buildmachine: str
    buildtime: str
    elapsedtime: int
    usertime: int
    systemtime: int
    roas: int
    failedroas: int
    invalidroas: int
    aspas: int
    failedaspas: int
    invalidaspas: int
    bgpsec_pubkeys: int
    certificates: int
    invalidcertificates: int
    nonfunctionalcas: int
    taks: int
    tals: int
    invalidtals: int
    talfiles: list[str]
    manifests: int
    failedmanifests: int
    crls: int
    gbrs: int
    repositories: int
    vrps: int
    uniquevrps: int
    vsps: int
    uniquevsps: int
    vaps: int
    uniquevaps: int
    cachedir_new_files: int
    cachedir_del_files: int
    cachedir_del_dirs: int
    cachedir_superfluous_files: int
    cachedir_del_superfluous_files: int


class ROA(TypedDict):
    """RPKI ROA"""

    asn: int
    prefix: str
    maxLength: int
    ta: str
    expires: int


class BGPSecKey(TypedDict):
    """BGPSec key"""

    asn: int
    key: str
    pubkey: str
    ta: str
    expires: int


class NonFuncCA(TypedDict):
    """Non functional CA"""

    location: str
    ta: str
    caRepository: str
    rpkiManifest: str
    ski: str


class ASPA(TypedDict):
    """ASPA object"""

    customer_asid: int
    expires: int
    providers: list[int]


class JSONContent(TypedDict):
    """Defines the fields in the JSON file"""

    metadata: JSONMetadata
    roas: list[ROA]
    bgpsec_keys: list[BGPSecKey]
    nonfunc_cas: list[NonFuncCA]
    aspas: list[ASPA]


class JSON(TypedDict):
    """Defines the data structure representing the JSON file"""

    content: JSONContent
    hash: str
    timestamp: float
    diffs: list[bytes]


class RPKIClient:
    """
    Interface for the JSON file as generated by rpki_client.
    """

    serial: int = 0
    path: str | os.PathLike[str]
    json: dict[int, JSON] = {}
    prefixes: list[bytes] = []

    def serialize_roa(self, roa: ROA, flags: int) -> bytes:
        """
        Serialize the ROA to bytes

        Arguments:
        ----------
        roa: ROA
            The ROA to serialize

        flags: int
            Either 0 for withdrawal or 1 for advertisement

        Returns:
        --------
        bytes: The serialized ROA
        """
        prefix = ip_network(roa["prefix"])
        if prefix.version == 4:
            return ipv4_prefix.serialize(
                prefix=prefix.network_address.packed,
                prefix_length=prefix.prefixlen,
                flags=flags,
                max_length=roa["maxLength"],
                asn=roa["asn"],
            )

        return ipv6_prefix.serialize(
            prefix=prefix.network_address.packed,
            prefix_length=prefix.prefixlen,
            flags=flags,
            max_length=roa["maxLength"],
            asn=roa["asn"],
        )

    def purge(self, expire: int = 7200):
        """
        Delete expired JSON files

        Arguments:
        ----------
        expire: int
            The amount of seconds after which a file is purged. Default: 7200
        """
        self.json = {
            _serial: _json
            for _serial, _json in self.json.items()
            if _json["timestamp"] > datetime.now(timezone.utc).timestamp() - expire
        }

    async def load(self, path: str | os.PathLike[str]) -> bool:
        """
        Loads the content of the file. Ignores files that have been already loaded.

        Arguments:
        ----------
        path: str | os.PathLike[str]
            Path to the file

        Returns:
        --------
        bool: True if the file was loaded, False if it was ignored
        """
        async with aiofiles.open(path, mode="rb") as file:
            data: bytes = await file.read()

        new_json_hash = hashlib.sha256(data).hexdigest()
        new_json: JSONContent = orjson.loads(data)  # pylint: disable=no-member

        # Check if the new and the current file are the same
        try:
            if new_json_hash == self.json[self.serial]["hash"]:
                return False
        except KeyError:
            pass

        diffs = []
        for _serial, _json in self.json.items():
            # Generate hashabale data structures
            old_roas: dict[Tuple[int, str, int], ROA] = {
                key: roa
                for roa in _json["content"]["roas"]
                if (key := (roa["asn"], roa["prefix"], roa["maxLength"]))
            }

            new_roas: dict[Tuple[int, str, int], ROA] = {
                key: roa
                for roa in new_json["roas"]
                if (key := (roa["asn"], roa["prefix"], roa["maxLength"]))
            }

            # Calculate changes
            removed_roa_ids: set[Tuple[int, str, int]] = set(old_roas) - set(new_roas)
            diffs = [
                self.serialize_roa(roa, 0) for _id in removed_roa_ids if (roa := old_roas[_id])
            ]

            added_roa_ids: set[Tuple[int, str, int]] = set(new_roas) - set(old_roas)
            diffs = diffs + [
                self.serialize_roa(roa, 1) for _id in added_roa_ids if (roa := new_roas[_id])
            ]

            # Add a new list of changes
            self.json[_serial]["diffs"] = diffs

        # Update the list of prefixes
        self.prefixes = [self.serialize_roa(roa, 1) for roa in new_json["roas"]]

        # Save new JSON
        self.serial = self.serial + 1
        self.json[self.serial] = JSON(
            content=new_json,
            hash=new_json_hash,
            timestamp=datetime.now(timezone.utc).timestamp(),
            diffs=[],
        )
        logger.info("Serial changed to: %d", self.serial)

        return True
